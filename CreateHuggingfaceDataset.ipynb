{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4ad41558-2e77-4cf1-b14c-4eb9dbde20b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e031240c0f4d5f80267095b8f9f858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset                   \n",
    "\n",
    "squad = load_dataset(\"squad\", split=\"train\")        \n",
    "squad.to_json(\"squad.json\")            \n",
    "\n",
    "# bla = load_dataset('json', data_files=\"./hfdataset/squad.json\")\n",
    "\n",
    "bla = load_dataset('json', data_files=\"./hfdataset/hf_datafile.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "708b3adb-329f-441d-94f0-fecbffbb8809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 2\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bee6045f-b1af-42eb-81de-e7272081992a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id = \"abc123\"\n",
    "title = \"\"\n",
    "context = \"\"\n",
    "question = \"\"\n",
    "answers = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0f40f6f6-b65f-4de7-83e5-6d1e4c4072c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "context = \"LlamaIndex is a data framework for LLM-based applications which benefit from context augmentation. Such LLM systems have been termed as RAG systems, standing for “Retrieval-Augemented Generation”. LlamaIndex provides the essential abstractions to more easily ingest, structure, and access private or domain-specific data in order to inject these safely and reliably into LLMs for more accurate text generation. It’s available in Python (these docs) and Typescript.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ee3a2572-e0d8-47eb-a060-594f26c1f67f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LlamaIndex is a data framework for LLM-based applications which benefit from context augmentation. Such LLM systems have been termed as RAG systems, standing for “Retrieval-Augemented Generation”. LlamaIndex provides the essential abstractions to more easily ingest, structure, and access private or domain-specific data in order to inject these safely and reliably into LLMs for more accurate text generation. It’s available in Python (these docs) and Typescript.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6fd824c-29f1-4ec9-b39b-c1e7cfb8b01f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \" What is LlamaIndex and what type of systems does it benefit?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a28c280b-066d-458c-8480-41d11a09714f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "answers =  [{\"text\": \"LlamaIndex is a data framework for Retrieval-Augmented Generation (RAG) systems, which are LLM-based applications that benefit from context augmentation.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c891b503-d7f2-481e-b936-35798e662197",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa1 = {   \n",
    "    \"id\" : id,\n",
    "    \"title\": title,\n",
    "    \"context\": context,\n",
    "    \"question\": question,\n",
    "    \"answers\": answers  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5e91940-6522-46cf-85aa-5fccbf98c71d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'abc123',\n",
       " 'title': '',\n",
       " 'context': 'LlamaIndex is a data framework for LLM-based applications which benefit from context augmentation. Such LLM systems have been termed as RAG systems, standing for “Retrieval-Augemented Generation”. LlamaIndex provides the essential abstractions to more easily ingest, structure, and access private or domain-specific data in order to inject these safely and reliably into LLMs for more accurate text generation. It’s available in Python (these docs) and Typescript.',\n",
       " 'question': ' What is LlamaIndex and what type of systems does it benefit?',\n",
       " 'answers': [{'text': 'LlamaIndex is a data framework for Retrieval-Augmented Generation (RAG) systems, which are LLM-based applications that benefit from context augmentation.'}]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c56cbc5f-1e0b-4584-bad4-2e7d068783ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import json\\ndatafile = open(\"hf_datafile.json\", \"w\")'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import json\n",
    "datafile = open(\"hf_datafile.json\", \"w\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3f189609-1e11-4c92-b72d-11a02345a7c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./hfdataset/hf_datafile.json\", \"a\", encoding ='utf8') as hf_datafile:\n",
    "    #hf_datafile.write(\"\\n\")\n",
    "    json.dump(qa1, hf_datafile, indent=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd9287-8e0d-4535-a3be-03b2aa7c7c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3787b-79e7-409b-a239-27820d5c3540",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
